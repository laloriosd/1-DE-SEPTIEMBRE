# -*- coding: utf-8 -*-
"""Dashboard de Documentos Recibidos 21

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kQp7dFARbAkfAypLPdvMDFp-_SF93EyG
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from PIL import Image # Import Pillow to handle images
import datetime
import json # Import json

# Configurar el tema de Streamlit para fondo blanco
st.set_page_config(layout="wide", page_title="Dashboard de Documentos Recibidos")

# Título del dashboard
st.title("Dashboard de Documentos Recibidos")

# Cargar el logo
try:
    # Asegúrate de que la ruta al archivo del logo sea correcta
    logo = Image.open('logobancoSANTANDER.png')
    # Puedes ajustar el tamaño del logo si es necesario
    # logo = logo.resize((100, 100)) # Ejemplo de redimensionamiento
except FileNotFoundError:
    st.error("Error: Asegúrate de que el archivo 'logobancoSANTANDER.png' esté en la misma carpeta que el script de Streamlit.")
    logo = None # Establecer logo a None if file not found
except Exception as e:
    st.error(f"Error al cargar el logo: {e}")
    logo = None

# Mostrar el logo si se cargó correctamente
if logo:
    st.image(logo, width=150) # Ajusta el ancho según sea necesario

# Add the file uploader
uploaded_file = st.file_uploader("Sube tu archivo Excel de notificaciones", type=["xlsx"])

# Load and process data
if uploaded_file is not None:
    try:
        # Load data from the uploaded file
        df_notificaciones = pd.read_excel(uploaded_file)
        # Assuming 'Latitud y longitud.xlsx' is still a local file and in the same directory
        df_coordenadas = pd.read_excel('Latitud y longitud.xlsx')

        # Limpieza y preparación de datos de notificaciones
        df_notificaciones.dropna(inplace=True) # Manejar nulos

        columns_to_clean = ['PLAZA/ENTIDAD', 'ZONA', 'MATERIA', 'TURNADO A']
        for col in columns_to_clean:
            df_notificaciones[col] = df_notificaciones[col].astype(str).str.replace(' ', '', regex=False) # Eliminar espacios y asegurar que sean strings

        # Renombrar columnas with underscore FIRST
        df_notificaciones.columns = df_notificaciones.columns.str.replace(' ', '_')

        # Then Categorize columns using the new names
        columns_to_categorize = ['ZONA', 'MATERIA', 'TURNADO_A']
        for col in columns_to_categorize:
            df_notificaciones[col] = df_notificaciones[col].astype('category') # Categorizar columnas


        # Prepare data for date modification
        # Convert date columns to datetime objects, coercing errors
        df_notificaciones['FECHA_RECEPCION'] = pd.to_datetime(df_notificaciones['FECHA_RECEPCION'], errors='coerce')
        df_notificaciones['FECHA_LIMITE'] = pd.to_datetime(df_notificaciones['FECHA_LIMITE'], errors='coerce')

        # Define the target date (September 11th)
        target_date = datetime.date(2025, 9, 11) # Assuming year 2025 based on sample data

        # Filter for ALTA and MEDIA urgency
        alta_media_mask = df_notificaciones['URGENCIA'].isin(['ALTA', 'MEDIA'])

        # Apply date modification based on MATERIA for ALTA/MEDIA urgency documents
        def adjust_fecha_recepcion(row):
            if row['URGENCIA'] in ['ALTA', 'MEDIA'] and pd.notnull(row['FECHA_RECEPCION']):
                if row['MATERIA'] == 'Mercantil':
                    return datetime.datetime.combine(target_date - datetime.timedelta(days=9), datetime.datetime.min.time())
                elif row['MATERIA'] in ['Penal', 'Civil', 'Familiar']:
                    return datetime.datetime.combine(target_date - datetime.timedelta(days=3), datetime.datetime.min.time())
            return row['FECHA_RECEPCION'] # Return original date if not ALTA/MEDIA or MATERIA not specified or date is NaT

        # Use apply with axis=1 to apply the function row-wise
        df_notificaciones['FECHA_RECEPCION'] = df_notificaciones.apply(adjust_fecha_recepcion, axis=1)


        # Preparar datos geográficos y combinar
        df_coordenadas = df_coordenadas.rename(columns={'Ciudad, Estado': 'PLAZA/ENTIDAD'}) # Renombrar columna para fusión

        # Asegurar que la columna de fusión en ambos DFs sea string para evitar problemas
        df_notificaciones['PLAZA/ENTIDAD'] = df_notificaciones['PLAZA/ENTIDAD'].astype(str)
        df_coordenadas['PLAZA/ENTIDAD'] = df_coordenadas['PLAZA/ENTIDAD'].astype(str)

        # Apply the same space removal to the merge key in df_coordenadas
        df_coordenadas['PLAZA/ENTIDAD'] = df_coordenadas['PLAZA/ENTIDAD'].str.replace(' ', '', regex=False)

        # Ensure Latitud and Longitud are strings in df_coordenadas before merge and handle potential NaNs
        df_coordenadas['Latitud'] = df_coordenadas['Latitud'].astype(str).fillna('') # Convert to string and fill NaN with empty string
        df_coordenadas['Longitud'] = df_coordenadas['Longitud'].astype(str).fillna('') # Convert to string and fill NaN with empty string

        df_merged = pd.merge(df_notificaciones, df_coordenadas, on='PLAZA/ENTIDAD', how='left')

        # Convertir latitud y longitud a numérico
        def convert_lat_lon(coord_series):
            # Ensure the series is of string type and handle potential NaNs/None explicitly
            coord_series_str = coord_series.astype(str).fillna('')

            # Only process non-empty string values that match the pattern
            valid_coords = coord_series_str[coord_series_str.str.match(r'([\d.]+)°\s*([NSEOW])')]

            if not valid_coords.empty:
                values = valid_coords.str.extract(r'([\d.]+)°\s*([NSEOW])')
                values.columns = ['Value', 'Direction']
                values['Value'] = pd.to_numeric(values['Value'], errors='coerce')
                values['Value'] = np.where(values['Direction'].isin(['O', 'S']), -values['Value'], values['Value'])
                # Reindex the result to match the original series index
                result = pd.Series(np.nan, index=coord_series.index, dtype=float) # Initialize with NaNs
                result.loc[valid_coords.index] = values['Value'] # Assign converted values to matching indices
                return result
            # Return a series of NaNs if no valid coordinates were found or input was empty/all null/non-matching
            return pd.Series(np.nan, index=coord_series.index)

        df_merged['Latitud'] = convert_lat_lon(df_merged['Latitud'])
        df_merged['Longitud'] = convert_lat_lon(df_merged['Longitud'])

        # Eliminar filas con coordenadas nulas after conversion
        df_merged.dropna(subset=['Latitud', 'Longitud'], inplace=True)

        # Convert 'FECHA_RECEPCION' to datetime (already done for modification, but ensure consistency)
        df_merged['FECHA_RECEPCION'] = pd.to_datetime(df_merged['FECHA_RECEPCION'], errors='coerce')


        # Add filters for Month and Year
        df_merged['Year'] = df_merged['FECHA_RECEPCION'].dt.year
        df_merged['Month'] = df_merged['FECHA_RECEPCION'].dt.month_name()

        # --- Add Filters for Year, Month, Plaza/Entidad, and Materia ---
        st.sidebar.header("Filtros")

        all_years = sorted(df_merged['Year'].unique())
        # Add a check for empty all_years
        if not all_years:
            st.warning("No hay datos de años disponibles en el archivo.")
            st.stop() # Stop execution if no years are found
        selected_year = st.sidebar.selectbox("Selecciona el Año", all_years)

        df_year_filtered = df_merged[df_merged['Year'] == selected_year].copy() # Use copy here


        all_months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
        available_months = sorted(df_year_filtered['Month'].unique(), key=all_months.index)
        # Add a check for empty available_months
        if not available_months:
            st.warning(f"No hay datos de meses disponibles para el año {selected_year}.")
            st.stop() # Stop execution if no months are found
        selected_month = st.sidebar.selectbox("Selecciona el Mes", available_months)

        df_month_filtered = df_year_filtered[df_year_filtered['Month'] == selected_month].copy() # Use copy here

        all_plazas = sorted(df_month_filtered['PLAZA/ENTIDAD'].unique())
        selected_plaza = st.sidebar.selectbox("Selecciona la Plaza/Entidad", ['Todas'] + all_plazas)

        all_materias = sorted(df_month_filtered['MATERIA'].unique())
        selected_materia = st.sidebar.selectbox("Selecciona la Materia", ['Todas'] + all_materias)


        # Apply filters
        df_filtered = df_month_filtered.copy()
        if selected_plaza != 'Todas':
            df_filtered = df_filtered[df_filtered['PLAZA/ENTIDAD'] == selected_plaza].copy() # Use copy here
        if selected_materia != 'Todas':
            df_filtered = df_filtered[df_filtered['MATERIA'] == selected_materia].copy() # Use copy here


        # --- Display KPIs for Urgency Levels ---
        st.subheader("Documentos por Nivel de Urgencia")
        urgency_counts = df_filtered['URGENCIA'].value_counts()

        col_alta, col_media, col_baja = st.columns(3)

        with col_alta:
            st.metric(label="Urgencia ALTA", value=urgency_counts.get('ALTA', 0))

        with col_media:
            st.metric(label="Urgencia MEDIA", value=urgency_counts.get('MEDIA', 0))

        with col_baja:
            st.metric(label="Urgencia BAJA", value=urgency_counts.get('BAJA', 0))

        # --- Display Detailed Table for ALTA and MEDIA Urgency ---
        st.subheader("Documentos con Urgencia ALTA o MEDIA")

        # Filter for ALTA or MEDIA urgency
        df_alta_media_urgency = df_filtered[df_filtered['URGENCIA'].isin(['ALTA', 'MEDIA'])].copy()

        # Select only the specified columns
        df_alta_media_urgency_subset = df_alta_media_urgency[['PLAZA/ENTIDAD', 'TURNADO_A']]

        if not df_alta_media_urgency_subset.empty:
            st.dataframe(df_alta_media_urgency_subset)
        else:
            st.info("No hay documentos con urgencia ALTA o MEDIA en los filtros seleccionados.")


        # --- Crear Visualizaciones ---

        if not df_filtered.empty:
            # Visualización 1: Número de Documentos Recibidos por Zona (Gráfico de Barras)
            zona_counts = df_filtered['ZONA'].value_counts().reset_index()
            zona_counts.columns = ['ZONA', 'Count']

            fig_bar = go.Figure(go.Bar(x=zona_counts['ZONA'], y=zona_counts['Count'],
                                       marker=dict(color=zona_counts['Count'], colorscale='Reds')))
            fig_bar.update_layout(title_text=f"Número de Documentos Recibidos por Zona en {selected_month}, {selected_year}")

            # Visualización 2: Porcentaje de Documentos con Confirmación 'Sí' (Gauge Chart)
            total_documents = len(df_filtered)
            # Asegurarse de que la columna CONFIRMACION esté en el formato correcto (string)
            df_filtered['CONFIRMACION'] = df_filtered['CONFIRMACION'].astype(str).str.strip()
            sí_confirmations_count = df_filtered[df_filtered['CONFIRMACION'] == 'Sí'].shape[0]

            sí_percentage = (sí_confirmations_count / total_documents) * 100 if total_documents > 0 else 0

            fig_gauge = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = sí_percentage,
                title = {'text': f"Porcentaje de Documentos con Confirmación 'Sí' en {selected_month}, {selected_year}"},
                gauge = {'axis': {'range': [None, 100]},
                         'bar': {'color': "darkred"},
                         'steps': [
                             {'range': [0, 50], 'color': 'salmon'},
                             {'range': [50, 100], 'color': 'indianred'}]
                        }))


            # Removed the map visualization as requested

            # Visualización 3 (New): Número de Documentos por Turnado A (Bar Chart)
            turnado_counts = df_filtered['TURNADO_A'].value_counts().reset_index()
            turnado_counts.columns = ['TURNADO_A', 'Count']
            # Filter out rows where Count is 0
            turnado_counts = turnado_counts[turnado_counts['Count'] > 0]


            fig_turnado = go.Figure(go.Bar(x=turnado_counts['TURNADO_A'], y=turnado_counts['Count'],
                                       marker=dict(color=turnado_counts['Count'], colorscale='Reds')))
            fig_turnado.update_layout(title_text=f"Número de documentos turnado a en {selected_month}, {selected_year}")


            # Visualización 4: Distribución de Documentos por Status (Pie Chart)
            status_counts = df_filtered['STATUS'].value_counts().reset_index()
            status_counts.columns = ['STATUS', 'Count']

            fig_pie = go.Figure(data=[go.Pie(labels=status_counts['STATUS'], values=status_counts['Count'], hole=.3,
                                                 marker=dict(colors=px.colors.sequential.Reds_r),
                                                 customdata=status_counts['STATUS'])]) # Add customdata to capture status
            fig_pie.update_layout(title_text=f"Distribución de Documentos por Status en {selected_month}, {selected_year}")

            # --- Mostrar visualizaciones en Streamlit in a layout suitable for 4 plots ---
            # We have 4 main visualizations: Bar (Zona), Gauge, Bar (Turnado A), and Pie.
            # We can arrange them in two columns.
            col1, col2 = st.columns(2)

            with col1:
                st.plotly_chart(fig_bar, use_container_width=True)
                st.plotly_chart(fig_turnado, use_container_width=True) # New chart here

            with col2:
                st.plotly_chart(fig_gauge, use_container_width=True)
                # Capture click event on the pie chart
                selected_status_data = st.plotly_chart(fig_pie, use_container_width=True, on_select="rerun")

            # --- Display filtered documents based on pie chart selection ---
            if selected_status_data and selected_status_data.selection:
                selected_status = selected_status_data.selection['points'][0]['customdata']
                st.subheader(f"Documentos con Status: {selected_status} y Fecha Límite Próxima")

                # Filter by selected status
                df_status_filtered = df_filtered[df_filtered['STATUS'] == selected_status].copy()

                # Filter by approaching deadline (e.g., within the next 7 days)
                today = datetime.date.today()
                approaching_deadline = today + datetime.timedelta(days=7)

                # Ensure 'FECHA_LIMITE' is in datetime format before filtering
                df_status_filtered['FECHA_LIMITE'] = pd.to_datetime(df_status_filtered['FECHA_LIMITE'])

                df_approaching_deadline = df_status_filtered[df_status_filtered['FECHA_LIMITE'].dt.date <= approaching_deadline]

                if not df_approaching_deadline.empty:
                    st.dataframe(df_approaching_deadline)
                else:
                    st.info(f"No hay documentos con status '{selected_status}' con fecha límite próxima.")

        else:
            st.warning("No hay datos disponibles para el mes y año seleccionados.")

    except FileNotFoundError:
        st.error("Error: Asegúrate de que el archivo 'Latitud y longitud.xlsx' esté en la misma carpeta que el script de Streamlit.")
    except Exception as e:
        st.error(f"An unexpected error occurred: {e}")
else:
    st.info("Por favor, sube un archivo Excel para comenzar.")